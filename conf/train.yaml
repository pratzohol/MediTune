defaults:
  - model: gemma
  - _self_

# Dataset config
dataset_path: dataset/processed
max_seq_length: 512

# Training parameters
per_device_train_batch_size: 1
per_device_eval_batch_size: 2
gradient_accumulation_steps: 4
num_train_epochs: 5
learning_rate: 2e-5
lr_scheduler_type: cosine
weight_decay: 0.01

# Logging & Checkpointing
output_dir: adapter
run_name: medmcqa_ft_${model.name}
logging_steps: 5
eval_strategy: steps
eval_steps: 10
save_strategy: steps
save_steps: 10
load_best_model_at_end: true
metric_for_best_model: eval_accuracy
greater_is_better: true

# Wandb
wandb:
  project: MediTune
  entity: pratzohol   # wandb username
  mode: disabled   # "disabled" to turn off

# Hydra
hydra:
  # output_subdir: null
  run:
    dir: ./hydra_logs/${now:%d-%m-%Y}/${now:%H-%M}
