defaults:
  - model: gemma
  - _self_

# Dataset config
dataset_path: dataset/processed
max_seq_length: 1024

# Training hyperparameters
per_device_train_batch_size: 4
per_device_eval_batch_size: 16
gradient_accumulation_steps: 4
num_train_epochs: 5
learning_rate: 2e-5
lr_scheduler_type: cosine
weight_decay: 0.01

# Logging & Checkpointing
logging_steps: 250
eval_strategy: epoch
output_dir: outputs
run_name: medmcqa_ft_${model.name}

# Wandb
wandb:
  project: MediTune
  entity: pratzohol   # wandb username
  mode: online   # "disabled" to turn off
