name: gemma
pretrained_model_name_or_path: google/gemma-2b

use_peft: false

load_in_4bit: false   # true if QLoRA
bnb_4bit_quant_type: nf4
bnb_4bit_use_double_quant: true
bnb_4bit_compute_dtype: float16

lora_r: 8
lora_alpha: 16
lora_dropout: 0.1
